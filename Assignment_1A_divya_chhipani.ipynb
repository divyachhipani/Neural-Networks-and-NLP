{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1A_divya_chhipani.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_yvQBKrD8Se"
      },
      "source": [
        "# **ECS 7001 - NN & NNLP**\n",
        "\n",
        "## **Lab 2: Skip-gram Model for Word2Vec**\n",
        "\n",
        "<br>\n",
        "\n",
        "**1st February**\n",
        "\n",
        "There are two Word2Vec architectures for creating word embeddings: the Continuous Bag of Words (CBOW) architecture and the Skip Gram architecture . In this lab, we will obtain our own word embeddings by training a skip-gram neural network model. Some of the code for this will be supplied here but in some sections, you will be required to implement the code yourself. Hints and\n",
        "tips will be provided.\n",
        "\n",
        "\n",
        "The skip gram model is essentially a feedforward neural network with one hidden layer, trained to predict the context word given a target word. There are two ways to train this model: (1) using a hierarchical softmax function and/or (2) by negative sampling. In this lab, we will be training using\n",
        "negative sampling. To train with negative sampling, the model is cast as a binary classification problem. The dataset would consist of positive and negative examples of the form:\n",
        "\n",
        "Input | label\n",
        "--| --\n",
        "(target_word, word_in_its_context)       |  1 \n",
        "(target_word, word_not_in_its_context)   |  0\n",
        "\n",
        "created from the sentences in a corpus. The exact number of positive and negative examples will depend on the window size, and the balance ratio of positive:negative examples.  \n",
        "\n",
        "As an example, consider the sentence: “ **The quick brown\n",
        "fox jumped over the lazy dog** ”. For the target word ' **fox** ' and a window size of 2, all the positive and negative examples drawn from this sentence would be:\n",
        "\n",
        "Input | label\n",
        "--| --\n",
        "(fox, the) | 0\n",
        "(fox, quick) | 1\n",
        "(fox, brown) | 1\n",
        "(fox, jumped) | 1\n",
        "(fox, over) |1\n",
        "(fox, lazy) | 0\n",
        "(fox, dog) | 0\n",
        "\n",
        "The model is trained to learn to predict 1 when a word is in the context of the target word (i.e.in the window of the target word) and 0 otherwise. The model thus learns the statistics of the given corpus: the frequency with two words appear together would determine how similar they are (similarity is usually measured using cosine distance). After training, the trained hidden layer weights are the word embeddings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep2X91YdJpkG"
      },
      "source": [
        "### **0. Prepare the environment**\n",
        "\n",
        "Open Google Colab or activate the virtual environment you’ve created"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Pi5uvTLRCo"
      },
      "source": [
        "### **1. Downloading the Corpus**\n",
        "\n",
        "Our training data will be comprised of 3 documents from the Gutenberg corpus. We can find this and other corpora in nltk https://www.nltk.org/book/ch02.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn7sWMG-KoBV",
        "outputId": "90177f01-d477-4aff-b67d-af5af18b4025"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "austen = gutenberg.sents('austen-sense.txt') + gutenberg.sents('austen-emma.txt') + gutenberg.sents('austen-persuasion.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYD16ST1MIOf"
      },
      "source": [
        "**Sanity check:**\n",
        "\n",
        "This training corpus contains 16498 sentences. The following print statement should return 16498."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCH0PmPcL83f",
        "outputId": "1c98378f-3f86-4937-b39c-7da78830b8f2"
      },
      "source": [
        "print(len(austen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APFWiEejv9i5",
        "outputId": "6013bbff-e441-43b9-c5c8-4a59264fc480"
      },
      "source": [
        "austen[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', 'Austen', '1811', ']']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c14vElNvMGX"
      },
      "source": [
        "### **2. Preprocessing the Training Corpus**\n",
        "\n",
        "In this section, you will write code to remove special characters, empty strings, digits and\n",
        "stopwords from the sentences and put all the words into lower cases. You might also consider removing sentences with fewer than 3 words or at least empty sentences.\n",
        "\n",
        "\n",
        "**Hints:**\n",
        "*   The corpus can be accessed as you would a tokenized list, a list of lists, each inner list contains all the tokens in the sentence. Eg:\n",
        "\\>> austen[0] =['[', 'Sense', 'and', 'Sensibility', 'by','Jane', 'Austen', '1811', ']']\n",
        "\n",
        "*   the python <string> library contains a variable “punctuation”, a string containing all\n",
        "the special characters.\n",
        "\n",
        "*   You might want to write a function that takes the corpus as an argument and returns the preprocessed corpus as a list of lists.\n",
        "\n",
        " Alternatively, you can use the keras preprocessing library to preprocess the text. More information on the library can be found here:\n",
        "https://keras.io/preprocessing/text/\n",
        "\n",
        "\n",
        "**Sanity check:**\n",
        "\n",
        "After preprocessing the corpus, as a sanity check, print the following line of code. If you chose removed sentences of length with fewer than 3 words, it should be about 13651. \n",
        "\n",
        "As a test for your preprocessing function, preprocess the sample below and print the output of your function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2SIxzvwybiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d307395e-e388-4aa8-8c4f-945218606951"
      },
      "source": [
        "import string\n",
        "def preprocess_corpus(corpus):\n",
        "  \n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    #corpus = re.sub(r'[^ A-Za-z0-9]','',corpus)\n",
        "    normalized_corpus = []\n",
        "    for i in corpus:\n",
        "        i = [j for j in i if j.isalpha()]\n",
        "        i = [c for c in i if c.strip() != 0]\n",
        "        i = [j.lower() for j in i]\n",
        "        i = [j for j in i if j not in stop_words]\n",
        "\n",
        "        #print(i)\n",
        "        if len(i) > 2:\n",
        "            #print(len(i))\n",
        "            normalized_corpus.append(i)\n",
        "    #normalized_corpus = [x for x in normalized_corpus if x]\n",
        "    return normalized_corpus\n",
        "\n",
        "\n",
        "normalized_corpus = preprocess_corpus(austen)\n",
        "print(normalized_corpus[1])\n",
        "print('The new length of the preprocessed output', len(normalized_corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['family', 'dashwood', 'long', 'settled', 'sussex']\n",
            "The new length of the preprocessed output 13923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc-EnfRXkZAA"
      },
      "source": [
        "**<i> <font color ='darkblue'> In this section, we perform basic pre-processing  steps like converting words into lowercase, tokenisation,   removing - punctuations, empty strings, spaces, stopwords. Finally, we checked the number of the remaining tokens and discard the sentences which have less than three tokens. </font></i>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ1qxoq-8Kob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399ea72c-16db-4516-999a-b7b6c28dec28"
      },
      "source": [
        "sample = austen[:2] + austen[100:102]\n",
        "preprocessed_sample = preprocess_corpus(sample)\n",
        "\n",
        "\n",
        "print(len(sample), sample)\n",
        "print()\n",
        "print(len(preprocessed_sample), preprocessed_sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 [['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', 'Austen', '1811', ']'], ['CHAPTER', '1'], ['But', ',', 'then', ',', 'if', 'Mrs', '.', 'Dashwood', 'should', 'live', 'fifteen', 'years', 'we', 'shall', 'be', 'completely', 'taken', 'in', '.\"'], ['\"', 'Fifteen', 'years', '!']]\n",
            "\n",
            "2 [['sense', 'sensibility', 'jane', 'austen'], ['mrs', 'dashwood', 'live', 'fifteen', 'years', 'shall', 'completely', 'taken']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rghchHA66d-V"
      },
      "source": [
        "### **3. Creating the Corpus Vocabulary and Preparing the Data**\n",
        "\n",
        "\n",
        "To prepare the data for machine learning, you will write code to prepare 3 variables:\n",
        "\n",
        "1. \\<word2idx>: a lookup table, a dictionary of (word index: word) pairs where **word index** is a unique integer assigned to every **unique word** in the corpus.\n",
        "2. \\<idx2word>: a dictionary of (token: token index), a reversal of \\<word2idx>. \n",
        "3. \\<sents_as_ids>: The input to the model cannot be text, rather, each word needs to be represented by a unique integer and each sentence an array of integers.\n",
        "\n",
        "\n",
        "The incomplete code provided below is just a guide. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmqUdSuU8PyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcaae55a-c353-4bcd-87bb-b5f55b008146"
      },
      "source": [
        "word2idx = {}\n",
        "idx2word = {}\n",
        "\n",
        "\n",
        "def prepareData(normalized_corpus):\n",
        "    i = 0\n",
        "    for sentence in normalized_corpus:\n",
        "        for word in sentence:\n",
        "            if word not in word2idx:\n",
        "                word2idx[word] = i\n",
        "                idx2word[i] = word\n",
        "                i+=1\n",
        "    return word2idx\n",
        "\n",
        "#idx2word = {}\n",
        "\n",
        "def prepareSentsAsId(normalized_corpus):\n",
        "    i=0\n",
        "    sents_as_ids = []\n",
        "    for sentence in normalized_corpus:\n",
        "        ids= []\n",
        "        for word in sentence:\n",
        "            ids.append(word2idx[word])\n",
        "        sents_as_ids.append(ids)\n",
        "    return sents_as_ids\n",
        "\n",
        "word2idx = prepareData(normalized_corpus)\n",
        "sents_as_ids =prepareSentsAsId(normalized_corpus)\n",
        "print('Number of unique words:', len(word2idx))\n",
        "print('\\nSample word2idx: ', list(word2idx.items())[:10])\n",
        "print('\\nSample idx2word:', list(idx2word.items())[:10])\n",
        "print('\\nSample sents_as_id:', prepareSentsAsId(preprocessed_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique words: 10084\n",
            "\n",
            "Sample word2idx:  [('sense', 0), ('sensibility', 1), ('jane', 2), ('austen', 3), ('family', 4), ('dashwood', 5), ('long', 6), ('settled', 7), ('sussex', 8), ('estate', 9)]\n",
            "\n",
            "Sample idx2word: [(0, 'sense'), (1, 'sensibility'), (2, 'jane'), (3, 'austen'), (4, 'family'), (5, 'dashwood'), (6, 'long'), (7, 'settled'), (8, 'sussex'), (9, 'estate')]\n",
            "\n",
            "Sample sents_as_id: [[0, 1, 2, 3], [68, 5, 194, 592, 33, 593, 285, 594]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVFa2cKwlUNA"
      },
      "source": [
        "**<i> <font color ='darkblue'> We create two dictionaries - word2idx which stores the word as the key and the value is a unique integer, and  idx2word which stores the unique integer as the key and the word as the value. We finally make a list which stores sentence as list of integers corresponding to the words in the sentence.</font></i>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCa7VGc59bCD"
      },
      "source": [
        "**Sanity Check**\n",
        "\n",
        "Copy and run the following lines of code:\n",
        "\n",
        "```\n",
        "print('Number of unique words:', len(word2idx)**\n",
        "```\n",
        "Returns a number between 9800 and 1200, the exact number depends on your preprocessing step. \n",
        "\n",
        "```\n",
        "print('\\nSample word2idx: ', list(word2idx.items())[:10])\n",
        "```\n",
        "\n",
        "Sample word2idx:  [('sense', 0), ('sensibility', 1), ('jane', 2), ('austen', 3), ('the', 4), ('family', 5), ('dashwood', 6), ('long', 7), ('settled', 8), ('sussex', 9)]\n",
        "\n",
        "\n",
        "```\n",
        "print('\\nSample idx2word:', list(idx2word.items())[:10])**\n",
        "```\n",
        "\n",
        "Sample idx2word: [(1, 'could'), (2, 'would'), (3, 'mr'), (4, 'mrs'), (5, 'must'), (6, 'said'), (7, 'one'), (8, 'much'), (9, 'miss'), (10, 'every')]\n",
        "\n",
        "```\n",
        "print('\\nSample sents_as_id:', prepareSentsAsId(preprocessed_sample))\n",
        "```\n",
        "\n",
        "Sample sents_as_id: [[0, 1, 2, 3], [41, 72, 6, 201, 619, 35, 620, 296, 621]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqw71xzzeYSm"
      },
      "source": [
        "After you have created the three variables, set the <vocab_size> and <embed_size> variables with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGsp5Lij8qUd"
      },
      "source": [
        "VOCAB_SIZE = len(word2idx) \n",
        "EMBED_SIZE = 100 # We are creating 100D embeddings."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_yjd5kgqiZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4acabe-6942-435b-9d3c-bf1b11572c94"
      },
      "source": [
        "print('Number of unique words:', len(word2idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique words: 10084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXhJNdf9TIed"
      },
      "source": [
        "### **4. Generating training instances**\n",
        "\n",
        "\n",
        "In this section we would generate the training examples of the format shown in introduction using the keras skip-gram generator https://keras.io/preprocessing/sequence/ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3g0FLzb7ivg"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import skipgrams\n",
        "skip_grams = []\n",
        "for sent in sents_as_ids:\n",
        "    skip_grams.append(tf.keras.preprocessing.sequence.skipgrams(\n",
        "        sent, VOCAB_SIZE, window_size=4, negative_samples=1.0, shuffle=True,\n",
        "        categorical=False, sampling_table=None, seed=None\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO0cpf1ImLbE"
      },
      "source": [
        "**<i> <font color ='darkblue'>  In this section, we create skipgrams using the keras inbuilt function wherein we pass the sentence  in the form of list of integers corresponding to the words in the sentence, vocabulary size and window size of 4 and enabling negative sampling such that it generates one negative sample for each positive sample.</font></i>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDyy65QlTyf2"
      },
      "source": [
        "**Sanity Check:**\n",
        "\n",
        "To view the skip_grams for the first sentence in the training data, run the line of code that follows. The output should look like:\n",
        "\n",
        "(austen (3), sensibility (1)) -> 1\n",
        "\n",
        "(austen (3), jane (2)) -> 1\n",
        "\n",
        "(jane (2), sensibility (1)) -> 1\n",
        "\n",
        "(jane (2), walked (2639)) -> 0\n",
        "\n",
        "(jane (2), partridge (7948)) -> 0\n",
        "\n",
        "(sensibility (1), austen (3)) -> 1\n",
        "\n",
        "(sensibility (1), beneficial (5587)) -> 0\n",
        "\n",
        "(sensibility (1), jane (2)) -> 1\n",
        "\n",
        "(sensibility (1), dreamt (8308)) -> 0\n",
        "\n",
        "(austen (3), perception (6543)) -> 0\n",
        "\n",
        "(jane (2), austen (3)) -> 1\n",
        "\n",
        "(austen (3), imposing (8622)) -> 0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa072PMvTvde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe35cd6-a6be-4250-85aa-fffeb9f0b2d5"
      },
      "source": [
        "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
        "\n",
        "for i in range(len(pairs)):\n",
        "         \tprint('({:s} ({:d}), {:s} ({:d})) -> {:d}'.format(\n",
        "        \t# the first word and its index\n",
        "        \tidx2word[pairs[i][0]], pairs[i][0],\n",
        "        \t# the second word and its index\n",
        "        \tidx2word[pairs[i][1]], pairs[i][1],\n",
        "        \t# the label\n",
        "        \tlabels[i]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(sensibility (1), jane (2)) -> 1\n",
            "(jane (2), austen (3)) -> 1\n",
            "(jane (2), sensibility (1)) -> 1\n",
            "(sensibility (1), gloominess (2240)) -> 0\n",
            "(jane (2), several (740)) -> 0\n",
            "(sensibility (1), changed (2560)) -> 0\n",
            "(jane (2), afloat (6357)) -> 0\n",
            "(sensibility (1), austen (3)) -> 1\n",
            "(austen (3), boys (2374)) -> 0\n",
            "(austen (3), sensibility (1)) -> 1\n",
            "(austen (3), jane (2)) -> 1\n",
            "(austen (3), ended (2969)) -> 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMQJAolZWVLx"
      },
      "source": [
        "### **5. Building the Skip-gram Neural Network Architecture**\n",
        "\n",
        "In this section we would be building the skip-gram neural network architecture using the Keras Functional API and the Sequential model introduced in the previous lab. https://keras.io/getting-started/functional-api-guide/ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi0JmuY-Tlsp"
      },
      "source": [
        "from keras.layers import Dot, Input\n",
        "from keras.layers.core import Dense, Reshape\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22d8UIg-cBOc"
      },
      "source": [
        "The skip-gram model is two input one output feedforward neural network with one hidden layer and this will be built over a series of steps.\n",
        "\n",
        "####**A. The first step is to initialize and transform the first input using the following lines of code:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggqykF7WUyGP"
      },
      "source": [
        "# The input is an array of target indices e.g. [2, 45, 7, 23,...9]\n",
        "target_word = Input((1,), dtype='int32')\n",
        "\n",
        "\n",
        "# feed the words into the model using the Keras <Embedding> layer. This is the hidden layer \n",
        "# from whose weights we will get the word embeddings.\n",
        "target_embedding = Embedding(VOCAB_SIZE, EMBED_SIZE, name='target_embed_layer',\n",
        "                        \tembeddings_initializer='glorot_uniform',\n",
        "                         \tinput_length=1)(target_word)\n",
        "\n",
        "\n",
        "# at this point, the input would of the shape (num_inputs x 1 x embed_size) and has to be flattened \n",
        "# or reshaped into a (num_inputs x embed_size) tensor.\n",
        "target_input = Reshape((EMBED_SIZE, ))(target_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXn_SVjHckwL"
      },
      "source": [
        "####**B. Write similar code for the ‘context_word’ input.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkCyRztYcMsp"
      },
      "source": [
        "# your code for the context_word goes here\n",
        "context_word = Input((1,), dtype='int32')\n",
        "\n",
        "\n",
        "# feed the words into the model using the Keras <Embedding> layer. This is the hidden layer \n",
        "# from whose weights we will get the word embeddings.\n",
        "context_embedding = Embedding(VOCAB_SIZE, EMBED_SIZE, name='context_embed_layer',\n",
        "                        \tembeddings_initializer='glorot_uniform',\n",
        "                         \tinput_length=1)(context_word)\n",
        "\n",
        "\n",
        "# at this point, the input would of the shape (num_inputs x 1 x embed_size) and has to be flattened \n",
        "# or reshaped into a (num_inputs x embed_size) tensor.\n",
        "context_input = Reshape((EMBED_SIZE, ))(context_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP_hHP2JnRdf"
      },
      "source": [
        "**<i> <font color ='darkblue'>We reuse the code for target embedding to create context embedding but we replace the target embedding input layer by creating an input layer for context and pass that to the context embedding layer. </font></i>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btNWVWRqdBJV"
      },
      "source": [
        "####**C. Merge the inputs.**\n",
        "\n",
        "Recall, each training instance is a (target_word, context_word) combination. Since we are trying to learn the degree of closeness between the two words, the model will compute the cosine distance between the two inputs using the <Dot> layer. https://keras.io/layers/merge/, hence fusing the two inputs into one.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL0_IgA0cYBx"
      },
      "source": [
        "merged_inputs = Dot(axes=-1, normalize=False)([target_input, context_input])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQEsxQ6We1Ob"
      },
      "source": [
        "####**D. The Output Layer**\n",
        "\n",
        "Pass the merged inputs (now a vector with a single number the cosine distance between the two input vectors for each word) into a sigmoid activated neuron. The output of this layer is the output of the model.\n",
        "\n",
        "**Hint**: Use the <Dense> layer ( https://keras.io/layers/core/ ), with a ‘sigmoid’ activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAUxsadqcj6Q"
      },
      "source": [
        "# your code for the output layer goes here\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Activation\n",
        "\n",
        "label = Activation('sigmoid')(merged_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unk2AJw5n2AF"
      },
      "source": [
        "**<i> <font color ='darkblue'>In the output layer, we use sigmoid function as activation function as we are expecting a binary output.</font></i>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQk1Yj8wfXrF"
      },
      "source": [
        "####**E. Initialize the model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHRICxY7cdBB"
      },
      "source": [
        "# label is the output of step D.\n",
        "model = Model(inputs=[target_word, context_word], outputs=[label])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdbRI0TGVZIt"
      },
      "source": [
        "####**F. Compile the model using the <model.compile> command.** Use Loss = ‘mean_squared_error’, optimizer = ‘rmsprop’."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LtWvavefueu"
      },
      "source": [
        "# your code here\n",
        "model.compile(loss='mse', optimizer = 'rmsprop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm_at8wcy-Tg"
      },
      "source": [
        "\n",
        "**<i> <font color ='darkblue'>In this code block, we compile the model where mean squared error is used as loss function and the optimizer is rmsprop. </font></i>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC7IShG_fczC"
      },
      "source": [
        "**Sanity check:**\n",
        "\n",
        "Visualize the model and the model summary by running the following lines of code. \n",
        "view the model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0ki6JDkgJNA",
        "outputId": "3ec05a2d-c29a-435d-ede2-d6427750d16f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "target_embed_layer (Embedding)  (None, 1, 100)       1008400     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "context_embed_layer (Embedding) (None, 1, 100)       1008400     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 100)          0           target_embed_layer[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 100)          0           context_embed_layer[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1)            0           reshape[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1)            0           dot[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 2,016,800\n",
            "Trainable params: 2,016,800\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VVPnyFhgVr9"
      },
      "source": [
        "####**G. Plot the model using ```vis utils```.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "vvfO-ensggr4",
        "outputId": "87c79588-0b8f-4880-e177-45abb0eaa156"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils import vis_utils\n",
        "SVG(vis_utils.model_to_dot(model, show_shapes=True, show_layer_names=True, dpi=60).create(prog='dot', format='svg'))  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"322pt\" viewBox=\"0.00 0.00 765.50 387.00\" width=\"638pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 761.5,-383 761.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139882059566608 -->\n<g class=\"node\" id=\"node1\">\n<title>139882059566608</title>\n<polygon fill=\"none\" points=\"46,-332.5 46,-378.5 318,-378.5 318,-332.5 46,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"112.5\" y=\"-351.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"179,-332.5 179,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"179,-355.5 237,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"237,-332.5 237,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-363.3\">[(None, 1)]</text>\n<polyline fill=\"none\" points=\"237,-355.5 318,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-340.3\">[(None, 1)]</text>\n</g>\n<!-- 139882061057040 -->\n<g class=\"node\" id=\"node3\">\n<title>139882061057040</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 364,-295.5 364,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"102\" y=\"-268.8\">target_embed_layer: Embedding</text>\n<polyline fill=\"none\" points=\"204,-249.5 204,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"204,-272.5 262,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"262,-249.5 262,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313\" y=\"-280.3\">(None, 1)</text>\n<polyline fill=\"none\" points=\"262,-272.5 364,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313\" y=\"-257.3\">(None, 1, 100)</text>\n</g>\n<!-- 139882059566608&#45;&gt;139882061057040 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139882059566608-&gt;139882061057040</title>\n<path d=\"M182,-332.3799C182,-324.1745 182,-314.7679 182,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"185.5001,-305.784 182,-295.784 178.5001,-305.784 185.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139881755486480 -->\n<g class=\"node\" id=\"node2\">\n<title>139881755486480</title>\n<polygon fill=\"none\" points=\"434,-332.5 434,-378.5 706,-378.5 706,-332.5 434,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500.5\" y=\"-351.8\">input_2: InputLayer</text>\n<polyline fill=\"none\" points=\"567,-332.5 567,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"596\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"567,-355.5 625,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"596\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"625,-332.5 625,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"665.5\" y=\"-363.3\">[(None, 1)]</text>\n<polyline fill=\"none\" points=\"625,-355.5 706,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"665.5\" y=\"-340.3\">[(None, 1)]</text>\n</g>\n<!-- 139881755486672 -->\n<g class=\"node\" id=\"node4\">\n<title>139881755486672</title>\n<polygon fill=\"none\" points=\"382.5,-249.5 382.5,-295.5 757.5,-295.5 757.5,-249.5 382.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-268.8\">context_embed_layer: Embedding</text>\n<polyline fill=\"none\" points=\"597.5,-249.5 597.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"597.5,-272.5 655.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"655.5,-249.5 655.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"706.5\" y=\"-280.3\">(None, 1)</text>\n<polyline fill=\"none\" points=\"655.5,-272.5 757.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"706.5\" y=\"-257.3\">(None, 1, 100)</text>\n</g>\n<!-- 139881755486480&#45;&gt;139881755486672 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139881755486480-&gt;139881755486672</title>\n<path d=\"M570,-332.3799C570,-324.1745 570,-314.7679 570,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"573.5001,-305.784 570,-295.784 566.5001,-305.784 573.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139882927293520 -->\n<g class=\"node\" id=\"node5\">\n<title>139882927293520</title>\n<polygon fill=\"none\" points=\"87.5,-166.5 87.5,-212.5 362.5,-212.5 362.5,-166.5 87.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"145\" y=\"-185.8\">reshape: Reshape</text>\n<polyline fill=\"none\" points=\"202.5,-166.5 202.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"202.5,-189.5 260.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"260.5,-166.5 260.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-197.3\">(None, 1, 100)</text>\n<polyline fill=\"none\" points=\"260.5,-189.5 362.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-174.3\">(None, 100)</text>\n</g>\n<!-- 139882061057040&#45;&gt;139882927293520 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139882061057040-&gt;139882927293520</title>\n<path d=\"M193.9779,-249.3799C198.4137,-240.8178 203.5271,-230.9477 208.3066,-221.7222\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.4448,-223.2732 212.9372,-212.784 205.2294,-220.0531 211.4448,-223.2732\" stroke=\"#000000\"/>\n</g>\n<!-- 139881755487632 -->\n<g class=\"node\" id=\"node6\">\n<title>139881755487632</title>\n<polygon fill=\"none\" points=\"403,-166.5 403,-212.5 693,-212.5 693,-166.5 403,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468\" y=\"-185.8\">reshape_1: Reshape</text>\n<polyline fill=\"none\" points=\"533,-166.5 533,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"533,-189.5 591,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"591,-166.5 591,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"642\" y=\"-197.3\">(None, 1, 100)</text>\n<polyline fill=\"none\" points=\"591,-189.5 693,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"642\" y=\"-174.3\">(None, 100)</text>\n</g>\n<!-- 139881755486672&#45;&gt;139881755487632 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139881755486672-&gt;139881755487632</title>\n<path d=\"M563.8718,-249.3799C561.6732,-241.0854 559.1493,-231.5633 556.7706,-222.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"560.117,-221.5534 554.1717,-212.784 553.3507,-223.347 560.117,-221.5534\" stroke=\"#000000\"/>\n</g>\n<!-- 139881755536464 -->\n<g class=\"node\" id=\"node7\">\n<title>139881755536464</title>\n<polygon fill=\"none\" points=\"226.5,-83.5 226.5,-129.5 523.5,-129.5 523.5,-83.5 226.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-102.8\">dot: Dot</text>\n<polyline fill=\"none\" points=\"291.5,-83.5 291.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"291.5,-106.5 349.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"349.5,-83.5 349.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"436.5\" y=\"-114.3\">[(None, 100), (None, 100)]</text>\n<polyline fill=\"none\" points=\"349.5,-106.5 523.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"436.5\" y=\"-91.3\">(None, 1)</text>\n</g>\n<!-- 139882927293520&#45;&gt;139881755536464 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139882927293520-&gt;139881755536464</title>\n<path d=\"M266.7834,-166.3799C284.5881,-156.5279 305.5226,-144.9442 324.2107,-134.6034\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.1256,-137.544 333.1808,-129.6399 322.7364,-131.4191 326.1256,-137.544\" stroke=\"#000000\"/>\n</g>\n<!-- 139881755487632&#45;&gt;139881755536464 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139881755487632-&gt;139881755536464</title>\n<path d=\"M499.8099,-166.3799C478.9017,-156.3488 454.2514,-144.5224 432.404,-134.0406\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"433.7615,-130.81 423.2315,-129.6399 430.7335,-137.1212 433.7615,-130.81\" stroke=\"#000000\"/>\n</g>\n<!-- 139881755611856 -->\n<g class=\"node\" id=\"node8\">\n<title>139881755611856</title>\n<polygon fill=\"none\" points=\"240.5,-.5 240.5,-46.5 509.5,-46.5 509.5,-.5 240.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-19.8\">activation: Activation</text>\n<polyline fill=\"none\" points=\"379.5,-.5 379.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"379.5,-23.5 437.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"437.5,-.5 437.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-31.3\">(None, 1)</text>\n<polyline fill=\"none\" points=\"437.5,-23.5 509.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139881755536464&#45;&gt;139881755611856 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139881755536464-&gt;139881755611856</title>\n<path d=\"M375,-83.3799C375,-75.1745 375,-65.7679 375,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"378.5001,-56.784 375,-46.784 371.5001,-56.784 378.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbOcZD6igpxy"
      },
      "source": [
        "###**6.Training the Model**\n",
        "\n",
        "Run the following block of code to train the model for 5 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmQN4r52gmLR",
        "outputId": "de4a85a1-45c9-4c31-8e32-edb5e12f0031"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    epoch_loss = 0\n",
        "    for i, sent_examples in enumerate(skip_grams):\n",
        "        target_wds = np.array([pair[0] for pair in sent_examples[0]], dtype='int32')\n",
        "        context_wds = np.array([pair[1] for pair in sent_examples[0]], dtype='int32')\n",
        "        labels = np.array(sent_examples[1], dtype='int32')\n",
        "        X = [target_wds, context_wds]\n",
        "        Y = labels\n",
        "        if i % 5000 == 0: \n",
        "        \tprint('Processed %d sentences' %i)\n",
        "        epoch_loss += model.train_on_batch(X, Y)\n",
        "    print('Processed all %d sentences' %i)\n",
        "    print('Epoch:', epoch, 'Loss:', epoch_loss, '\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed 0 sentences\n",
            "Processed 5000 sentences\n",
            "Processed 10000 sentences\n",
            "Processed all 13922 sentences\n",
            "Epoch: 1 Loss: 2590.3710163030773 \n",
            "\n",
            "Processed 0 sentences\n",
            "Processed 5000 sentences\n",
            "Processed 10000 sentences\n",
            "Processed all 13922 sentences\n",
            "Epoch: 2 Loss: 2197.0485896533355 \n",
            "\n",
            "Processed 0 sentences\n",
            "Processed 5000 sentences\n",
            "Processed 10000 sentences\n",
            "Processed all 13922 sentences\n",
            "Epoch: 3 Loss: 2141.438904635608 \n",
            "\n",
            "Processed 0 sentences\n",
            "Processed 5000 sentences\n",
            "Processed 10000 sentences\n",
            "Processed all 13922 sentences\n",
            "Epoch: 4 Loss: 2095.4548662034795 \n",
            "\n",
            "Processed 0 sentences\n",
            "Processed 5000 sentences\n",
            "Processed 10000 sentences\n",
            "Processed all 13922 sentences\n",
            "Epoch: 5 Loss: 2033.8358700186945 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj6BiOKfiI7R"
      },
      "source": [
        "The training takes about 10 minutes to run.\n",
        "\n",
        "<br>\n",
        "\n",
        "In the introduction, we outlined two approaches to training using the skipgram architecture. In this tutorial, we implemented the negative sampling training approach. While waiting for the training to complete, read this article http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/. It contains the skipgram model with softmax training. \n",
        "\n",
        "<br>\n",
        "\n",
        "After reading the article, answer the following questions:  \n",
        "●\tWhat would the inputs and outputs to the model be?\n",
        "\n",
        "●\tHow would you use the Keras framework to create this architecture?\n",
        "\n",
        "●\tWhat are the reasons this training approach is \n",
        "considered inefficient?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV8S8ZdO9usT"
      },
      "source": [
        "Question 1: What would the inputs and outputs to the model be? <br/>\n",
        "Answer:\n",
        "**<i> <font color ='darkblue'> Input to the mentioned model is the one-hot vector representation for target words which are the input words here and the output is in the form of probability distribution which is the output that we get from the softmax function.</font></i>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qUOIMW7-Fnv"
      },
      "source": [
        "Question 2: How would you use the Keras framework to create this architecture? <br/>\n",
        "Answer: **<i> <font color ='darkblue'>The model architecture will consist of an input layer which takes in input of size equal to the length of one-hot representation of words, a hidden dense layer with 300 units, followed by the output layer with softmax as the activation function as we want the output to be a probability distribution for each word in the vocabulary. The model makes use of gradient descent as an optimizer and has MSE as the loss function. Code for this model is given below:\n",
        "</font></i>** \n",
        "\n",
        "input_layer = Input(shape = (10000,)) <br/>\n",
        "hidden_dense_layer = Dense(300)(input_layer) <br/>\n",
        "output_layer = Dense(10000, activation = 'softmax')(hidden_dense_layer) <br/>\n",
        "model = Model(inputs = input_layer, outputs = output_layer) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8s3_Hf9-NFi"
      },
      "source": [
        "Question 3: What are the reasons this training approach is considered inefficient? <br/>\n",
        "Answer: **<i> <font color ='darkblue'>The model takes in 10000 words in the vocabulary and has 300 features resulting in 3M weights which needs to be trained and this is computationaly costly and also risks overfitting. Also, probability of choosing common words is higher as compared to the probability of choosing rarer words for which Negative Sampling could be considered.  </font></i>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwz_8kTZ6UVF"
      },
      "source": [
        "###**7. Getting the Word Embeddings**\n",
        "\n",
        "The word embeddings are the weights of the target word embedding layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiQTO6VgcN90",
        "outputId": "8dc9f94a-5139-4c4d-da7b-baf804efa424"
      },
      "source": [
        "word_embeddings = model.get_layer('target_embed_layer').get_weights()[0] \n",
        "\n",
        "# should return (VOCAB_SIZE, EMBED_SIZE)\n",
        "print(word_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10084, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33-QRJFv6v5t"
      },
      "source": [
        "Print out a few words and their embeddings using the next block of code. Your output may not be exactly as above but the command should print 10 words and their respective vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HffZwwLUcXb1",
        "outputId": "c643733d-f251-41d5-bc37-656b7704c8ad"
      },
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "print(DataFrame(word_embeddings, index=idx2word.values()).head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   0         1         2   ...        97        98        99\n",
            "sense        0.022132 -0.021818 -0.014919  ... -0.023806  0.006483 -0.005479\n",
            "sensibility  0.006892  0.013031  0.009114  ... -0.033868 -0.024282 -0.008528\n",
            "jane        -0.006343 -0.114453 -0.115419  ...  0.026720  0.011113 -0.004903\n",
            "austen      -0.017108 -0.004009  0.012293  ... -0.038474 -0.023167  0.030859\n",
            "family      -0.056714 -0.051039 -0.032007  ... -0.036367 -0.015014  0.068005\n",
            "dashwood    -0.088098  0.094064  0.062374  ... -0.083655  0.032214  0.117312\n",
            "long         0.002460  0.024011 -0.032046  ...  0.042740 -0.071517  0.116967\n",
            "settled      0.015020  0.012760 -0.009831  ... -0.013363 -0.016120 -0.001037\n",
            "sussex      -0.031684  0.029758  0.025280  ...  0.017535 -0.027242  0.019020\n",
            "estate      -0.007590  0.031553  0.018864  ... -0.004872  0.013545  0.041610\n",
            "\n",
            "[10 rows x 100 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ki8NtrS7ezr"
      },
      "source": [
        "###**8.  Measuring Similarity Between Word Pairs**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbb-uoe666oV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1c5a67-c4f2-488a-e8ae-54f2f4914d4d"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_matrix = cosine_similarity(word_embeddings)\n",
        "\n",
        "# should print(VOCAB_SIZE, VOCAB_SIZE)\n",
        "print(similarity_matrix.shape)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10084, 10084)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0fyfgvB90G5"
      },
      "source": [
        "###**9. Exploring and Visualizing your Word Embeddings using t-SNE**\n",
        "\n",
        "**A.\tGet the most similar words to the search items in the list below**\n",
        "\n",
        "search_terms = ['family', 'love', 'equality', 'wisdom', 'justice',  'humour', 'rejection']\n",
        "\n",
        "\n",
        "**Sanity check:**\n",
        "The similar words obtained would depend on your training but the above command should print a dictionary. Each key is a search term and each value is a list of the 5 words the model predicts to be most similar to the key word. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWbSfqYschRs",
        "outputId": "644ac186-7cbc-460e-da0e-bc5890161580"
      },
      "source": [
        "import numpy\n",
        "import operator\n",
        "import itertools\n",
        "search_terms = ['think', 'thought', 'mr', 'friend', 'love', 'disdain']\n",
        "\n",
        "# write code to get the 5 words most similar to the words in search_terms\n",
        "similar_words = dict()\n",
        "def take(n, iterable):\n",
        "    \"Return first n items of the iterable as a list\"\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "for search_word in search_terms:\n",
        "    print('Search term: '+search_word)\n",
        "    index = word2idx[search_word] \n",
        "    similar_word_vector = similarity_matrix[index] \n",
        "    similar_word_dict = {idx2word[i]:similar_word_vector[i] for i in range(len(similar_word_vector))} \n",
        "    sorted_items = dict(sorted(similar_word_dict.items(),key=operator.itemgetter(1), reverse=True)) \n",
        "    out = dict(itertools.islice(sorted_items.items(), 5)) \n",
        "    print('Similar words: ')\n",
        "    print(list(out.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search term: think\n",
            "Similar words: \n",
            "['think', 'hope', 'never', 'business', 'family']\n",
            "Search term: thought\n",
            "Similar words: \n",
            "['thought', 'never', 'much', 'father', 'indeed']\n",
            "Search term: mr\n",
            "Similar words: \n",
            "['mr', 'knightley', 'robert', 'elliot', 'elton']\n",
            "Search term: friend\n",
            "Similar words: \n",
            "['friend', 'weston', 'way', 'soon', 'first']\n",
            "Search term: love\n",
            "Similar words: \n",
            "['love', 'rather', 'mother', 'said', 'set']\n",
            "Search term: disdain\n",
            "Similar words: \n",
            "['disdain', 'gracious', 'precise', 'profits', 'willingness']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGpRXAme33OA"
      },
      "source": [
        " **<i> <font color ='darkblue'>In this task, we fetch the row corresponding to each word we want to find similar words for where the row has values for similarity measure between the word under consideration and the word in each column. We use each index in the extracted list to extract the word using idx2word and create a dictionary similar_word_dict such that key is the extracted similar word and value is the similarity measure. We sort this dictionary items by descending order of similarity measure and display the top 5 dictionary items.  </font></i>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I_X9W-vGXiZ"
      },
      "source": [
        "**B. Plot the words in the dictionary above using t-SN**E https://lvdmaaten.github.io/tsne/ \n",
        "\n",
        "Plot 50 of the word embeddings using the code snippets below:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMnyCjS4cnb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "7e1d679f-50e4-4b79-c0e3-a4039a705639"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tsne = TSNE(perplexity=3, n_components=2, init='pca', n_iter=5000, method='exact')\n",
        "np.set_printoptions(suppress=True)\n",
        "plot_only = 50 \n",
        "\n",
        "T = tsne.fit_transform(word_embeddings[:plot_only, :])\n",
        "labels = [idx2word[i+1] for i in range(plot_only)]\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.scatter(T[:, 0], T[:, 1])\n",
        "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
        "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points', ha='right', va='bottom')                      \t                        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsCVTRUMP1qi"
      },
      "source": [
        "**10. Resources used**\n",
        "\n",
        "http://jalammar.github.io/illustrated-word2vec/\n",
        "https://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/ \n",
        "https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa \n",
        "https://adventuresinmachinelearning.com/word2vec-keras-tutorial/ \n",
        "https://www.tensorflow.org/tutorials/representation/word2vec#the_skip-gram_model \n",
        "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py \n",
        "\n"
      ]
    }
  ]
}